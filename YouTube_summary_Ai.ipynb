{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c289aaa",
   "metadata": {},
   "source": [
    "# 모듈설치\n",
    "1. 유튜브 영상 다운로드 (음성만 다운로드, mp3) - PyTube\n",
    "2. Speech to Text (Transcribe) - OpenAI Whisper (Local)\n",
    "3. Map-reduce summariation - LangChain, OpenAI ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec995d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg => conda 로 설치하셈\n",
    "# !pip install -q openai-whisper pytube\n",
    "# !pip install -q openai tiktoken langchain\n",
    "# !pip install gradio\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "291e819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "\n",
    "# yt = YouTube('https://www.youtube.com/watch?v=JGdlvUffk5Y')\n",
    "\n",
    "# yt.streams.filter(only_audio=True).first().download(\n",
    "#     output_path='.', filename='input.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b5f45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위스퍼 로드 (음성 -> 텍스트)\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "615260a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## 스플릿 로드\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f74574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_documents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstuff\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StuffDocumentsChain\n\u001b[0;32m      8\u001b[0m openai_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m() \u001b[38;5;66;03m# api 키는 유출이 안되게 하라\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, openai_api_key\u001b[38;5;241m=\u001b[39mopenai_api_key)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Map prompt\u001b[39;00m\n\u001b[0;32m     13\u001b[0m map_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mThe following is a set of documents\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;132;01m{docs}\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124mBased on this list of docs, please identify the main themes\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124mHelpful Answer:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Lib\\site-packages\\langchain\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "openai_api_key = input() # api 키는 유출이 안되게 하라\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "# Map prompt\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "\n",
    "# Reduce prompt\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{doc_summaries}\n",
    "Take these and distill it into a final, consolidated summary of the main themes.\n",
    "The final answer is a single paragraph of about 100 words and must be in Korean.\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "# 1. Reduce chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")\n",
    "\n",
    "# 2. Map chain\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7853e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "def extract_video_id(url):\n",
    "    youtube_regex = (r'(https?://)?(www\\.)?'\n",
    "        '(youtube|youtu|youtube-nocookie)\\.(com|be)/'\n",
    "        '(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})')\n",
    "    youtube_pattern = re.compile(youtube_regex)\n",
    "    match = youtube_pattern.match(url)\n",
    "    if not match:\n",
    "        return None\n",
    "    return match.group(6)\n",
    "\n",
    "def summarize(url):\n",
    "    yt = YouTube(url)\n",
    "\n",
    "    yt.streams.filter(only_audio=True).first().download(\n",
    "        output_path='.', filename='input.mp3')\n",
    "\n",
    "    result = model.transcribe(\"input.mp3\")\n",
    "\n",
    "    docs = [Document(page_content=x) for x in text_splitter.split_text(result[\"text\"])]\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "    sum_result = map_reduce_chain.run(split_docs)\n",
    "\n",
    "    video_id = extract_video_id(url)\n",
    "    embed = f\"\"\"<iframe width='560' height='315' src='https://www.youtube.com/embed/{video_id}' frameborder='0' allowfullscreen></iframe>\"\"\"\n",
    "\n",
    "    return sum_result, embed\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=summarize,\n",
    "    inputs=gr.Textbox(label=\"URL\"),\n",
    "    outputs=[gr.TextArea(label=\"Summary\"), gr.HTML()],\n",
    "    # outputs=gr.TextArea(label=\"Summary\"),\n",
    ")\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456851e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
